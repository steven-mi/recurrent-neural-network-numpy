{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important imports\n",
    "import numpy as np\n",
    "from translator import Translator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "text = open('data/toy.txt', 'r').read()\n",
    "#text = 'Hallo'\n",
    "text_length = len(text)\n",
    "print(text_length)\n",
    "characters = list(set(text))\n",
    "\n",
    "# initializing translator and creating training data\n",
    "tl = Translator(characters)\n",
    "X = tl.to_one_hot(text)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_length = X.shape[0]\n",
    "hidden_size = 50\n",
    "learning_rate = 1e-8\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnable parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxh = np.random.randn(hidden_size, tl.characters_size) * 0.01\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "Why = np.random.randn(tl.characters_size, hidden_size) * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and backward pass\n",
    "\n",
    "\n",
    "### Forward\n",
    "$$\n",
    "z_t = W_{xh} * x_t + W_{hh} * h_{t-1} \\\\\n",
    "h_t = tanh(z_t) \\\\\n",
    "y_t = W_{hy} * h_t \\\\\n",
    "p_t = softmax(y_t) = \\frac{e^{y_t}}{\\sum_k e^{y_k}} \\\\\n",
    "L_t = - log (p_t) \\\\\n",
    "L = \\sum_t L_t\n",
    "$$\n",
    "\n",
    "### Backward\n",
    "\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{hy}} = \\sum_t \\frac{\\partial L_t}{\\partial p_t}  \\frac{\\partial p_t}{\\partial y_t}  \\frac{\\partial y_t}{\\partial W_{hy}}\n",
    "$$\n",
    "\n",
    "#### Part 2\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{hh}} = \\sum_t\n",
    "\\sum_k^{t-1} \\frac{\\partial L_t}{\\partial h_t}\n",
    "\\frac{\\partial h_t}{\\partial h_k} \n",
    "\\frac{\\partial h_k}{\\partial z_k} \n",
    "\\frac{\\partial z_k}{\\partial W_{hh}} \n",
    "$$\n",
    "\n",
    "#### Part 3\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{xh}} = \\sum_t\n",
    "\\sum_k^{t-1} \\frac{\\partial L_t}{\\partial h_t}\n",
    "\\frac{\\partial h_t}{\\partial h_k} \n",
    "\\frac{\\partial h_k}{\\partial z_k} \n",
    "\\frac{\\partial z_k}{\\partial W_{xh}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(X, targets, hprev):\n",
    "    # forward pass\n",
    "    zt, ht, yt, pt, loss = [], [], [], [], 0\n",
    "    ht.append(hprev)\n",
    "    for t in range(X.shape[0]):\n",
    "        zt.insert(t, np.dot(Wxh, X[t].reshape(len(characters), 1)) + np.dot(Whh, ht[t - 1]))\n",
    "        ht.insert(t, np.tanh(zt[t]))\n",
    "        yt.insert(t, np.dot(Why, ht[t]))\n",
    "        pt.insert(t, np.exp(yt[t]) / np.sum(np.exp(yt[t])))\n",
    "        loss += -np.sum(np.log(pt[t])* targets[t])/X.shape[0]\n",
    "\n",
    "    # backward pass\n",
    "    dWhh, dWxh, dWhy = np.zeros_like(Whh), np.zeros_like(Wxh), np.zeros_like(Why)\n",
    "    for t in reversed(range(X.shape[0])):\n",
    "        dout = np.copy(pt[t])\n",
    "        dout[targets[t]] -= 1\n",
    "        dWhy += np.dot(dout, ht[t].T)\n",
    "        dh = np.dot(Why.T, dout)\n",
    "        dtanh = (1 - ht[t] * ht[t]) * dh\n",
    "        dWxh += np.dot(dtanh, X[t].reshape(len(characters), 1).T)\n",
    "        dWhh += np.dot(dtanh, ht[t - 1].T)\n",
    "        \n",
    "    # gradient clipping\n",
    "    for dparam in [dWxh, dWhh, dWhy]:\n",
    "        np.clip(dparam, -5, 5, out=dparam)\n",
    "    return loss, dWhh, dWxh, dWhy, ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Wxh, Whh, Why, hprev):\n",
    "    zt, ht, yt, pt = [], [], [], []\n",
    "    ht.append(hprev)\n",
    "    prediction = ''\n",
    "    for t in range(X.shape[0]):\n",
    "        zt.insert(t, np.dot(Wxh, X[t].reshape(len(characters), 1)) + np.dot(Whh, ht[t - 1]))\n",
    "        ht.insert(t, np.tanh(zt[t]))\n",
    "        yt.insert(t, np.dot(Why, ht[t]))\n",
    "        pt.insert(t, np.exp(yt[t] - np.max(yt[t])) / np.sum(np.exp(yt[t] - np.max(yt[t]))))\n",
    "        prediction += characters[np.argmax(pt[t])]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:01,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758575168997929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:00<00:01,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758575168997891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:01,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7585751689978646\n",
      "3.7585751689978424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:01<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7585751689978246\n",
      "3.758575168997807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:01<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758575168997792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:01<00:00,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758575168997779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.758575168997763\n",
      "3.7585751689977513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ht = [np.zeros((hidden_size, 1))]\n",
    "grad_squared_xh, grad_squared_hh, grad_squared_hy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "for ite in tqdm(range(iterations)):\n",
    "    y = np.append(X[1:X.shape[0]],X[0])\n",
    "    loss, dWhh, dWxh, dWhy, ht = forward_and_backward(X, y, ht[-1])\n",
    "    # adagrad\n",
    "    grad_squared_xh += dWxh ** 2\n",
    "    grad_squared_hh += dWhh ** 2\n",
    "    grad_squared_hy += dWhy ** 2\n",
    "    Wxh -= dWxh / np.sqrt(grad_squared_xh + 1e-7) * learning_rate\n",
    "    Whh -= dWhh / np.sqrt(grad_squared_hh + 1e-7) * learning_rate\n",
    "    Why -= dWhy / np.sqrt(grad_squared_hy + 1e-7) * learning_rate\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eWF’ kSA1l’ S’wS SsWFl,W11hwlwlWP’FS’FSlWl lowSwWF’1ll0SeWA1Sx1WPw1SlW’FowlW lwwWF’ kSA1l’ S 1wW,WlwSWdA FS’Fl1h Fl’WFS FlS,e kSw’m1SWdA FS,ew,l’WFwW’Pw0S1W’w1SWlW1hwSlW’FowlW lwwWF’ kSA1l’ S’wS Suk1wwSlWSWdA F’Wl0SeWF’ kSA1l’ SA o1wSWdA FS’Fl1h Fl’WFSAdFWwAW,eSsWF11F’1Flw FlSAdFWwm wW1hSlW FS,e kSw’m1SWdA FS’Fl1h Fl’WF1S’WwA o1wSdkWu k’x l’WFS S,e k’Wl1S’Wwd’11wS SsW FF1SmW,S’Fl,W11hl1lwx1WPw1SlWS1Fx,ewwSlW1Aw1k11w1S FlS’Ww kwWSu1Fem’Ww 111wWPw’Fl1hF l’WF kS,ew,l’WFwW’PwSxW1lW1hS’WwSudw’FewwSW,SwWF’ k0uueWF’ kSA1l’ SA o1wS’Ww1 wlwmW,Sx1WPw1SlWSsWAAdF’F l1S FlS’Fl1h Flwx’WWw1 FWwWlW1hS FlW’A1S FlmW1heS’FSlW1SxW,wl0SW1WPw1Ss FSwW lwsWFF1FlwlWSlW1’mSm A’w’1wS FlSwW11lwWFewSFWSA ll1hSWWmwm mSlW1lw meSmeWAS1 FWwWlW1h0SnW lw u’w’WlwlWShwWWmwAW,eSsWFl1FlhuueWF’ kSA1l’ SW wSA l1SsWAAdF’F l’WFS SwWlwAW,eS1 w’1hSlW FS111hSu1mW,e0SnWm1Sx’WWw SlWdFWwWmS SudWlWFSx1WPw1SsWdklwsWAAdF’F l1Sx’WWw FluWllw FlwxW1heS’FSlW1SxW,wl0S1euw’W1wSwdFWw wSP F1uWWowA o1wSsWAAdF’F l’WFSx’WWwWlW1hwS FS1 wlwl,wo0SP F1uWWow’Ao,W11lwsWAAdFF’F l’WFS FlS111FSA l1SsWAAdF’F l’WFS Su1ll1hS1Fx1h’1FF10SP F1uWWow kkWmwx1Ww1SlWSwW meSxWWlWw1SxWwWwsWAA1Flw1S FlS1’1xwx1WPw1owSx1hwWF kS’FmW,A l’WF0S1’WWw kAWwWwNmmSA’wk’WFSdw1hwS FFWdFlw1Sm F1uWWow’wSsWFw’ 1helwlWSu1SWFeSWmSlW1SAWwWwxWPdk,mSwWF’ kSA1l’ Sx1uw’W1w1AWwWwWmSlW1Sx1WPw1Sdw1S’Ww wS SwduwW’WdW1SmW,S,e kSw’m1SWdA FS’Fl1h Fl’WF0Suu0FFW,l’FdSlWSPW,u1w1SlW1heS meS uWdWw’wu’wk’WFSwWF’ kSA1l’ S FFWdFlwS kkSW11hSlW1SxW,wl1SlW1w1S FFWdFlwSA o1wS kAWwWw kkSWmSlW1SsWdFl,’1wSWmSlW1SxW,wlwsWFF1Fl1lwx’WWw1 FWwWlW1h0eWF’ kSA1l’ S’wS S11hlwsWAAWFS’FSlWl lowSAWl1hFSxW,wl1SwWF’ kSA1l’ S’wSsWFw’ 1helwlWSu1SWFeSWmSWdA F’WlowSd,e l1wWw FW’111A1FlwS FlS FFWAow’wWA1Flw0Sn111hSu1mW,eSWdA FwSx1heSsWFF1Fl1lwlWS1 FWwWlW1hS wS’FSlWl lowSxW,wl0S FlS kAWwWw111hluWllwW wS SP F1uWWow FFWdFl1SlW1heS meS uWdWwNmmSA’wk’WFSP F1uWWow FFWdFlw0SP F1uWWow kkWmw’WwSdw1hwSlWSsW lwx’WWw1 FWwWlW1h1SlWSw11S1 FWwWlW1howSx’Fld,ew1S FlSlWSsWAA1FlwWFS FlwxWwW0S1W’FWw’wS11hlwdw1mdkS’FSlW1Sudw’FewwS FlSA mo1l’FdSxW,wl0uunW1S u’w’WlwlWSw11SWlW1howSx’Fld,ew1SsWAA1Flw1S FlSWlW1hSx1hwWF kS’FmW,A l’WF1SA o1wSx,’1,Flw SA jW,S’wwd10SW1WPw1SFWSwWFd1hSW 11Sx,’1,l1Sw’11w1Su1F dw1S111hluWllwxWwWwW’wSx1hwWF kS’FmW,A l’WFSWFSlW1S’Fl1hFel1\n"
     ]
    }
   ],
   "source": [
    "print(predict(X, Wxh, Whh, Why, ht[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
