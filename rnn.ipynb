{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important imports\n",
    "import numpy as np\n",
    "from translator import Translator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_length = 5\n",
    "hidden_size = 100\n",
    "learning_rate = 1e-1\n",
    "iterations = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "#text = open('data/toy.txt', 'r').read()\n",
    "text = 'Hallo'\n",
    "text_length = len(text)\n",
    "print(text_length)\n",
    "characters = list(set(text))\n",
    "\n",
    "# initializing translator and creating training data\n",
    "tl = Translator(characters)\n",
    "X = tl.to_one_hot(text)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnable parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxh = np.random.randn(hidden_size, tl.characters_size) * 0.01\n",
    "Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "Why = np.random.randn(tl.characters_size, hidden_size) * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and backward pass\n",
    "\n",
    "\n",
    "### Forward\n",
    "$$\n",
    "z_t = W_{xh} * x_t + W_{hh} * h_{t-1} \\\\\n",
    "h_t = tanh(z_t) \\\\\n",
    "y_t = W_{hy} * h_t \\\\\n",
    "p_t = softmax(y_t) = \\frac{e^{y_t}}{\\sum_k e^{y_k}} \\\\\n",
    "L_t = - log (p_t) \\\\\n",
    "L = \\sum_t L_t\n",
    "$$\n",
    "\n",
    "### Backward\n",
    "\n",
    "\n",
    "#### Part 1\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{hy}} = \\sum_t \\frac{\\partial L_t}{\\partial p_t}  \\frac{\\partial p_t}{\\partial y_t}  \\frac{\\partial y_t}{\\partial W_{hy}}\n",
    "$$\n",
    "\n",
    "#### Part 2\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{hh}} = \\sum_t\n",
    "\\sum_k^{t-1} \\frac{\\partial L_t}{\\partial h_t}\n",
    "\\frac{\\partial h_t}{\\partial h_k} \n",
    "\\frac{\\partial h_k}{\\partial z_k} \n",
    "\\frac{\\partial z_k}{\\partial W_{hh}} \n",
    "$$\n",
    "\n",
    "#### Part 3\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{xh}} = \\sum_t\n",
    "\\sum_k^{t-1} \\frac{\\partial L_t}{\\partial h_t}\n",
    "\\frac{\\partial h_t}{\\partial h_k} \n",
    "\\frac{\\partial h_k}{\\partial z_k} \n",
    "\\frac{\\partial z_k}{\\partial W_{xh}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(X, targets, hprev):\n",
    "    # forward pass\n",
    "    zt, ht, yt, pt, loss = [], [], [], [], 0\n",
    "    ht.append(hprev)\n",
    "    for t in range(X.shape[0]):\n",
    "        zt.insert(t, np.dot(Wxh, X[t].reshape(len(characters), 1)) + np.dot(Whh, ht[t - 1]))\n",
    "        ht.insert(t, np.tanh(zt[t]))\n",
    "        yt.insert(t, np.dot(Why, ht[t]))\n",
    "        pt.insert(t, np.exp(yt[t]) / np.sum(np.exp(yt[t])))\n",
    "        loss += -np.sum(np.log(pt[t])* targets[t])/X.shape[0]\n",
    "\n",
    "    # backward pass\n",
    "    dWhh, dWxh, dWhy = np.zeros_like(Whh), np.zeros_like(Wxh), np.zeros_like(Why)\n",
    "    for t in reversed(range(X.shape[0])):\n",
    "        dout = np.copy(pt[t])\n",
    "        dout[targets[t]] -= 1\n",
    "        dWhy += np.dot(dout, ht[t].T)\n",
    "        dh = np.dot(Why.T, dout)\n",
    "        dtanh = (1 - ht[t] * ht[t]) * dh\n",
    "        dWxh += np.dot(dtanh, X[t].reshape(len(characters), 1).T)\n",
    "        dWhh += np.dot(dtanh, ht[t - 1].T)\n",
    "        \n",
    "    # gradient clipping\n",
    "    for dparam in [dWxh, dWhh, dWhy]:\n",
    "        np.clip(dparam, -5, 5, out=dparam)\n",
    "    return loss, dWhh, dWxh, dWhy, ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Wxh, Whh, Why, hprev):\n",
    "    zt, ht, yt, pt = [], [], [], []\n",
    "    ht.append(hprev)\n",
    "    prediction = ''\n",
    "    for t in range(X.shape[0]):\n",
    "        zt.insert(t, np.dot(Wxh, X[t].reshape(len(characters), 1)) + np.dot(Whh, ht[t - 1]))\n",
    "        ht.insert(t, np.tanh(zt[t]))\n",
    "        yt.insert(t, np.dot(Why, ht[t]))\n",
    "        pt.insert(t, np.exp(yt[t] - np.max(yt[t])) / np.sum(np.exp(yt[t] - np.max(yt[t]))))\n",
    "        prediction += characters[np.argmax(pt[t])]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 430.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haaaa\n",
      "1.1090356277198574\n",
      "Haaaa\n",
      "1.1090357774217896\n",
      "Haaaa\n",
      "1.109036521661166\n",
      "Haaaa\n",
      "1.1090379776387476\n",
      "Haaaa\n",
      "1.1090404339888909\n",
      "Haaaa\n",
      "1.1090444744690982\n",
      "Haaaa\n",
      "1.1090512509960408\n",
      "Haaaa\n",
      "1.1090630632985374\n",
      "Haaaa\n",
      "1.1090845821912914\n",
      "Haaaa\n",
      "1.1091254240187751\n",
      "Haaaa\n",
      "1.1092055310371\n",
      "Haaaa\n",
      "1.1093662371756658\n",
      "Haaaa\n",
      "1.1096922656943744\n",
      "Haaaa\n",
      "1.1103522753951727\n",
      "Haaaa\n",
      "1.111660230895775\n",
      "Haaaa\n",
      "1.114114757094356\n",
      "Haaaa\n",
      "1.1182442780666915\n",
      "Haaaa\n",
      "1.1242025925296644\n",
      "Haaaa\n",
      "1.1318744775053264\n",
      "Haaaa\n",
      "1.1412726992930804\n",
      "Haaaa\n",
      "1.1524809714170017\n",
      "Haaaa\n",
      "1.1655922154399234\n",
      "Haaaa\n",
      "1.1807080763457578\n",
      "Haaaa\n",
      "1.197950077128129\n",
      "Haaaa\n",
      "1.2174693398417324\n",
      "Haaaa\n",
      "1.2394502423321847\n",
      "Haaaa\n",
      "1.2641056590609066\n",
      "Haaaa\n",
      "1.2916628965346584\n",
      "Haaaa\n",
      "1.3223406375990425\n",
      "Haaaa\n",
      "1.3563186043875795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ht = [np.zeros((100, 1))]\n",
    "for ite in tqdm(range(iterations)):\n",
    "    for i in range(0, X.shape[0], network_length):\n",
    "        X_train = X[i:i + network_length]\n",
    "        y_train = X[i + 1:i + 1 + network_length]\n",
    "        if y_train.shape[0] != network_length:\n",
    "            y_train = np.append(y_train, X[0])\n",
    "        loss, dWhh, dWxh, dWhy, ht = forward_and_backward(X_train, y_train, ht[-1])\n",
    "        Wxh -= dWxh * learning_rate\n",
    "        Whh -= dWhh * learning_rate\n",
    "        Why -= dWhy * learning_ratess\n",
    "    print(predict(X, Wxh, Whh, Why, ht[-1]))\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Haaaa'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X, Wxh, Whh, Why, ht[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
